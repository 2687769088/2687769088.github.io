# 毕业论文（设计）开题报告

<style>html body{ font-family: "华文中宋"; }</style>

|   学校   |    学院    |        专业 （方向）         |   学号   | 姓名 |
| :------: | :--------: | :--------------------------: | :------: | :--: |
| 中山大学 | 计算机学院 | 计算机科学与技术（超算方向） | 17341163 | 吴坎 |

## 论文（设计）题目

基于华为 Atlas 800-9000 服务器的 HPL-AI 算法实现和优化

## 目的

HPL（the High-Performance Linpack Benchmark）是国际上最流行的用于测试高性能计算机系统浮点性能的 benchmark，其通过对高性能计算机采用高斯消元法求解一元 N 次稠密线性代数方程组的测试，评价高性能计算机的浮点性能。随着混合精度算法在现代超级计算应用程序中的普及，HPC 专家 Jack Dongarra 提出了一个新的基准，即 [HPL-AI](https://icl.bitbucket.io/hpl-ai/)，以评估超级计算机在混合精度计算上的性能。[当 NVIDIA 在当时全球最快的超级计算机 Summit 上运行 HPL-AI 测试时，该系统达到了前所未有的性能水平，接近 550 petaflop，比其在 TOP500 榜单上的官方性能快了 3 倍](https://blogs.nvidia.com/blog/2019/06/17/hpc-ai-performance-record-summit/)。

然而，HPL-AI 基准是一年前才提出来的较新基准，目前尚未有公开的实现方法。我们计划完成首个开源的 HPL-AI 算法实现，并移植到[华为 Atlas 800-9000 AI 训练服务器](https://e.huawei.com/cn/products/cloud-computing-dc/atlas/atlas-800-training-9000)上进行基准测试，该服务器提供了单机 2.24 PFLOPS 超强半精度算力。

## 思路

根据 HPL-AI 基准的限制（详见【附录：HPL-AI 的规则】），我们需要在 HPL 算法上做如下工作：

1. 修改测试矩阵生成算法，生成对角优势矩阵。
2. 修改 HPL 算法运算过程为半精度运算。
3. 在上述两步的得到低精度解的基础上实现并行 64 位精度的数值迭代方法，提升解的精度。
4. 基于计算平台的环境做针对性优化。

这也将是我们的实现思路。

## 方法

HPL-AI 基准基于 HPL 基准，因此虽然目前尚未有公开的 HPL-AI 实现方法，一些适用于 CUDA 异构计算环境的 HPL 算法实现（详见【附录：可供参考的开源实现】）也会对我们的实现有指导意义。

首先，我们需要在已有的开源代码基础上实现一个正确的 HPL-AI 实现。这个 HPL-AI 算法的实现应当是前后分离的，使用到的矩阵运算应当被分离成单独的接口，以方便后续的代码移植工作。

其次，我们需要完成 HPL-AI 算法在[华为 Atlas 800-9000 AI 训练服务器](https://e.huawei.com/cn/products/cloud-computing-dc/atlas/atlas-800-training-9000)上的移植工作，并针对 Atlas 计算环境做初步优化。

最后，我们需要在多 Atlas 节点的计算集群上进行 HPL-AI 基准测试，并针对计算环境和集群的网络环境做更深入的优化。

## 相关支持条件

算法正确性的验证工作在天河二号的 GPU 集群上完成，其中混合精度的过程也可以使用单精度实现。

移植工作在广州超算中心的单 Atlas 800-9000 计算节点完成，该节点位于超算四楼二号机房 2F13 的 5 号\~ 8 号机位。

最后的 benchmark 过程计划在鹏城实验室的云脑 II 集群上进行。鹏城云脑 II 主要有 4 个 Altast900 集群，多达 500 个计算节点，理论 AI 算力高达 1000P，即每秒百亿亿次计算能力。

## 进度安排

截至开题报告完成时（2020 年 11 月 12 日），我们已经在天河二号的 GPU 节点上完成了算法正确性的初步验证工作，正在进行代码的前后端分离工作和到单 Atlas 节点的移植工作。

预计年底前可以初步完成到 Atlas 单节点的移植工作，后续 benchmark 过程及其调优过程待安排。

预计在毕业论文定稿截止日（2021 年 4 月 18 日）前可以按期完成毕业论文（设计）。

## 附录

### HPL-AI 的规则

参照 [Rules](https://icl.bitbucket.io/hpl-ai/rules/)。基准的思路是：

1. 对矩阵进行混合精度分解，然后计算较低精度分解（LU 分解）下得到的近似解。
2. 在低精度解上使用 64 位精度的迭代方法（如 GMRES）迭代，最终达到 64 位精度下的 LU 分解所能达到的精确度。在迭代算法中，应使用低精度 LU 因子作为预条件（preconditioner）。

基准应在 HPL 基准上进行修改，并对矩阵生成器进行修改。修改后的生成器应该产生一个非对称矩阵，对角线元素是该行的非对角线元素的总和。容易知道该矩阵是对角优势（diagonally dominant）矩阵（自己补充：用直接法或迭代法解系数矩阵为对角优势矩阵的线性代数方程组时，可以保证算法的稳定性或收敛性）。

为了在所有计算机上实现性能报告的一致性，在基准测试过程中求解低精度方程组时使用的算法必须在数值上符合 LU 因式分解。特别地，即使不需要双精度运算，所需的浮点操作数也必须是 $\frac{2}{3}n^3+O(n^2)$。

算法的误差由此式确定：$\frac{\Vert Ax-b\Vert_{\infty}}{\Vert A\Vert_{\infty} \Vert x\Vert_{\infty} + \Vert b\Vert_{\infty}} \times (n \times \epsilon)^{-1}$，其中 $\epsilon$ 是 64 位浮点算术中的机器精度（在 IEEE 标准下是 $2^{−53}$），$n$ 是问题的大小。对 $n$ 没有限制，但如果误差大于 $16$，则结果无效。

允许在浮点格式范围内对结果进行平衡缩放（自己补充：浮点数是非定点数，因此越靠近 0 浮点数分布越稠密），但所需的时间必须包含在求解时间中。

分解过程可以在其构造过程中使用混合精度，例如，panel 分解和三角矩阵求解可以用 32 位精度完成，舒尔补充过程（Schur complement，$A_{2,2} \leftarrow A_{2,2} - A_{2,1} \times A_{1,1}^{-1} \times A_{1,2}$ 形式的矩阵乘法）可以用 32 位累加的 16 位精度来计算。

计算效率基于解决问题的时间：较低精度分解矩阵、可能的防止溢出的平衡放缩过程、执行 GMRES 或使用 LU 因子作为预条件的使用 64 位浮点运算的其他迭代方法。如果需要 50 次以上的迭代，则该方法应返回失败，并且本次运行无效。

在计算效率时，用$\frac{2}{3} n^3 + \frac{3}{2} n^2$（LU 因式分解需要 $\frac{2}{3} n^3 - \frac{1}{2} n^2$，$2n^2$ 用于随后的后向和正向求解）除以总的解算时间得到每秒的运算速率。

作为提交结果的一部分，提交者被希望提供提交中使用的算法的详细说明。

### 可供参考的开源实现

#### hpl-2.0_FERMI_v15

NVIDIA 的提供的最新开源版本，上次更新时间为 2012 年。从 <https://developer.nvidia.com/rdp/assets/cuda-accelerated-linpack-linux64> 可以下载 linpack for Linux64，剩余内容可参照[如何自行编译 HPL-GPU 来测试 Benchmark](https://blog.csdn.net/m0_37929348/article/details/105155627)。

> Yes, the best HPL performance will come from HPL code specifically provided on a case-by-case basis by NVIDIA. It is not publicly available, and the hpl-2.0_FERMI_v15 will not achieve highest performance on GPUs newer than FERMI.

根据英伟达官方技术人员在 [Poor results from CUDA Linpack on K80](https://forums.developer.nvidia.com/t/poor-results-from-cuda-linpack-on-k80/47602) 的回答，这个**开源的**最新版本 `hpl-2.0_FERMI_v15.tgz` 并不能在比 FERMI 更新的架构上获得最佳的性能表现，而想最大程度挖掘机器性能只能使用 NVIDIA 提供的预编译好的二进制包。

#### hpl-gpu

[hpl-gpu](https://github.com/davidrohr/hpl-gpu) 是开源代码仓库网站 GitHub 上能够找到的最热门的实现，上次更新时间为 2015 年，目前已获得![Star](https://img.shields.io/github/stars/davidrohr/hpl-gpu.svg)。

[hpl-gpu](https://github.com/davidrohr/hpl-gpu) 同样基于 HPL-2.0。相较于 hpl-2.0_FERMI_v15，它的优点是将 HPL 算法的前端和后端分离，后端矩阵运算全部交由 [CALDGEMM](https://github.com/davidrohr/caldgemm) 库实现，相较于前者更容易被移植到新的计算环境上。
